{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7316566,"sourceType":"datasetVersion","datasetId":4245661}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Social Media Sentiments Analysis\n\nSocial media analysis is to understand audience, develop creative contents, increase traffic and sales, boost ROI, and improve strategic decision-making to achieve social media goals. Audience analysis helps improving customer experience, brand perception, and marketing strategy. Meanwhile, sentiment analysis is to find out how audience feel about your brand on social media via engagement activities such as likes, follows, clicks, retweets, comments, impressions, interests, and behaviours, etc. These metrics help marketing campains and measuring key performance indicators(KPIs). ","metadata":{}},{"cell_type":"markdown","source":"# About the dataset\n\nThe dataset captures audience emotions, trends, and interactions across different social media platform; Instagram, Facebook, Tweeter. It provides a snapshot of user generated content, encompassing text, timestamps, hashtags, countries, likes and retweets. It can be leveraged for diverse analytical purposes such as sentiment analysis, temporal analysis, user behaviour insights, platform specific analysis, hashtag trends, geographical analysis, user identification, and cross-analysis.\n\n[Data Source](https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset)\n\n* Text: User-generated content showcasing sentiments\n* Sentiment: Categorized emotions\n* Timestamp: Date and time information\n* User: Unique identifiers of users contributing\n* Platform: Social media platform where the content originated\n* Hashtags: Identifies trending topics and themes\n* Likes: Quantities user engagement\n* Retweets: Reflects content popularity\n* Country: Geographical origin of each post","metadata":{}},{"cell_type":"markdown","source":"# Identify objective\n\n* Understand data to interpret insights about how customer feel on social media\n* Analyze and visualize audience sentiments to improve audience experience\n* Deliver strategic marketing metrics to achieve socal media goals","metadata":{}},{"cell_type":"markdown","source":"# 1. Import libaries and Load data","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/social-media-sentiments-analysis-dataset/sentimentdataset.csv\")\ndf.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Preprocessing: Inspect and Clean Data","metadata":{}},{"cell_type":"code","source":"print('Columns of dataset: ', df.columns, '\\n')\nprint('Dimension of dataset: ', df.shape, '\\n')\nprint('Infomation of dataset: ', df.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum() #<--- null value: none","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.duplicated().sum() #<---duplicates: none","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Preprocessing: Wrangle and Transform data","metadata":{}},{"cell_type":"code","source":"# Drop unrelevant and unclear no-name columns from the dataset\ndf1=df.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check statistical distribution of numerical variables\ndf1.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check object columns: count of all values in the column, unique value, top value, frequency of value\ndf1.describe(include=['object'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**pandas.Series.str.strip()**\n\nStrip whitespaces (including newlines) or a set of specified characters from each string in the Series/Index from left and right sides. Replaces any non-strings in Series with NaNs.\n\nExample: \n- Before using str.strip(): ' Twitter  ', ' Twitter ', ' Instagram ', ' Facebook '\n- After using str.strip(): 'Twitter', 'Instagram', 'Facebook'\n","metadata":{}},{"cell_type":"code","source":"# Series.str.strip() in pandas: Remove leading and trailing characters in Series/Index.\ndf1['Text']= df1['Text'].str.strip()\ndf1['Sentiment']= df1['Sentiment'].str.strip()\ndf1['User']= df1['User'].str.strip()\ndf1['Platform']= df1['Platform'].str.strip()\ndf1['Hashtags']= df1['Hashtags'].str.strip()\ndf1['Country']= df1['Country'].str.strip()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# to see unique values in 'Platform' column\nprint(\"Print unique values in 'Platform'column: \", df1['Platform'].unique(), '\\n')\nprint(\"Value counts in 'Platform' column: \", '\\n', df1['Platform'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1.sample(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transform the 'Timestamp' column to two columns, 'Date', 'Time'\nimport datetime as dt\ndf1['time'] = pd.to_datetime(df1.Timestamp)\ndf1['Date'] = df1['time'].dt.date\ndf1['Time'] = df1['time'].dt.time\n#df1['new_Day']=df1['time'].dt.day\ndf1['Weekday']=df1['time'].dt.weekday  #<--- weekday value: 0 ~ 6\n#df1.drop(['Timestamp', 'time'], axis=1) #<--- not working in here\ndf1.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop two columns: 'timestamp', 'time'\ndf2=df1.drop(['Timestamp', 'time'], axis=1)\ndf2.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transform name of the column and create new column 'Month_name' using replace() function\ndf2['Monthname']=df2['Month'].replace([1,2,3,4,5,6,7,8,9,10,11,12], ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\ndf2['Weekdayname']=df2['Weekday'].replace([0,1,2,3,4,5,6], ['Mon','Tue','Wed','Thur','Fri','Sat','Sun'])\ndf2.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2.drop('Weekday', axis=1).sample(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the value of columns: 'Monthname', 'Weekdayname'using np.unique()\nprint('Name of value in the Monthname column:', df2.Monthname.unique())\nprint('Name of value in the Weekdayname column: ', df2.Weekdayname.unique())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Analyze and visualize data","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 5))\ndf2['Sentiment'].value_counts().nlargest(20).plot(kind='bar')\nplt.title(\"Kinds of Sentiment in descending order\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#\nplt.figure(figsize=(10, 5))\ndf2['Platform'].value_counts().plot(kind='pie', autopct='%1.1f%%')\nplt.title(\"Proportion of Platform\")\n#plt.legend()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#\nplt.figure(figsize=(10, 5))\ndf2['Country'].value_counts().nlargest(15).plot(kind='bar')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for column in df2[['Year', 'Likes', 'Retweets']]:\n    print(f\"Maxiumn value: {column}:{df2[column].max()} | Minimum value: {column}:{df2[column].min()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#\nplt.figure(figsize=(10, 5))\ndf2.groupby('Country')['Likes'].sum().nlargest(15).plot(kind='bar')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#\nplt.figure(figsize=(10, 5))\ndf3=df2.groupby('Hashtags')['Retweets'].sum().nlargest(10).sort_values(ascending=False)\ndf3.plot(kind='bar')\nplt.xticks(rotation=80)\n#control test angle","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create variable 'Twitter' \nTwitter=df2[df2['Platform']=='Twitter']\ndf5=Twitter.groupby('Year')['Likes'].sum().reset_index()\nplt.figure(figsize=(10, 5))\nsns.lineplot(data=df5, x='Year', y='Likes', marker='o')\nplt.title(\"Accumulative 'Likes' over years on Twitter\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# iterrows(): iterate over DataFrame rows as (index, Series) pairs.\nInstagram=df2[df2['Platform']=='Instagram']\ndf_ins=Instagram.groupby('Year')['Retweets'].sum().reset_index()\n\nplt.figure(figsize=(12, 5))\nsns.lineplot(data=df_ins, x='Year', y='Retweets', marker='o')\nfor index, value in df_ins.iterrows():\n    plt.text(value['Year'], value['Retweets'], str(value['Retweets']), ha='left', va='bottom')\nplt.title(\"Accumulative 'Retweets' over time on Instagram\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}